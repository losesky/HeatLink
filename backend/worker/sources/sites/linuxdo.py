import logging
import datetime
from typing import List, Dict, Any, Optional

from worker.sources.base import NewsItemModel
from worker.sources.rest_api import RESTNewsSource

logger = logging.getLogger(__name__)


class LinuxDoNewsSource(RESTNewsSource):
    """
    Linuxä¸­å›½ï¼ˆlinux.doï¼‰æ–°é—»æºé€‚é…å™¨
    """
    
    def __init__(
        self,
        source_id: str = "linuxdo",
        name: str = "Linuxä¸­å›½",
        api_url: str = "https://linux.do/latest.json?order=created",
        update_interval: int = 1800,  # 30åˆ†é’Ÿ
        cache_ttl: int = 900,  # 15åˆ†é’Ÿ
        category: str = "technology",
        country: str = "CN",
        language: str = "zh-CN",
        config: Optional[Dict[str, Any]] = None,
        mode: str = "latest"  # æ¨¡å¼ï¼šlatest æˆ– hot
    ):
        self.mode = mode
        
        # æ ¹æ®æ¨¡å¼è®¾ç½®API URL
        if mode == "hot":
            api_url = "https://linux.do/top/daily.json"
        
        config = config or {}
        config.update({
            "headers": {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
                "Accept": "application/json"
            }
        })
        
        super().__init__(
            source_id=source_id,
            name=name,
            api_url=api_url,
            update_interval=update_interval,
            cache_ttl=cache_ttl,
            category=category,
            country=country,
            language=language,
            custom_parser=self.custom_parser
        )
    
    def custom_parser(self, data: Dict[str, Any]) -> List[NewsItemModel]:
        """
        è‡ªå®šä¹‰è§£æå™¨ï¼Œå¤„ç†Linuxä¸­å›½çš„JSONæ•°æ®
        """
        news_items = []
        
        try:
            # è·å–ä¸»é¢˜åˆ—è¡¨
            topic_list = data.get("topic_list", {})
            topics = topic_list.get("topics", [])
            
            for topic in topics:
                try:
                    # æ£€æŸ¥ä¸»é¢˜æ˜¯å¦å¯è§ã€æœªå½’æ¡£ã€æœªç½®é¡¶
                    visible = topic.get("visible", False)
                    archived = topic.get("archived", False)
                    pinned = topic.get("pinned", False)
                    
                    if not visible or archived or pinned:
                        continue
                    
                    # è·å–ä¸»é¢˜ID
                    topic_id = topic.get("id")
                    if not topic_id:
                        continue
                    
                    # è·å–æ ‡é¢˜
                    title = topic.get("title")
                    if not title:
                        continue
                    
                    # ç”ŸæˆURL
                    url = f"https://linux.do/t/topic/{topic_id}"
                    
                    # è·å–åˆ›å»ºæ—¶é—´
                    created_at_str = topic.get("created_at")
                    published_at = None
                    if created_at_str:
                        try:
                            published_at = datetime.datetime.fromisoformat(created_at_str.replace("Z", "+00:00"))
                        except Exception as e:
                            logger.error(f"Error parsing date {created_at_str}: {str(e)}")
                    
                    # è·å–æ‘˜è¦
                    excerpt = topic.get("excerpt")
                    
                    # è·å–å›å¤æ•°å’Œç‚¹èµæ•°
                    reply_count = topic.get("reply_count", 0)
                    like_count = topic.get("like_count", 0)
                    
                    # åˆ›å»ºæ–°é—»é¡¹
                    news_item = self.create_news_item(
                        id=str(topic_id),
                        title=title,
                        url=url,
                        content=None,
                        summary=excerpt,
                        image_url=None,
                        published_at=published_at,
                        extra={
                            "is_top": False,
                            "mobile_url": url,
                            
                            
                            "like_count": like_count,
                            "comment_count": reply_count,
                            "info": f"ğŸ‘ {like_count} ğŸ’¬ {reply_count}"
                        }
                    )
                    
                    news_items.append(news_item)
                except Exception as e:
                    logger.error(f"Error processing LinuxDo topic: {str(e)}")
                    continue
            
            # å¦‚æœæ˜¯æœ€æ–°æ¨¡å¼ï¼ŒæŒ‰åˆ›å»ºæ—¶é—´æ’åº
            if self.mode == "latest":
                news_items.sort(key=lambda x: x.published_at if x.published_at else datetime.datetime.now(), reverse=True)
            
            return news_items
        except Exception as e:
            logger.error(f"Error parsing LinuxDo response: {str(e)}")
            return []


class LinuxDoLatestNewsSource(LinuxDoNewsSource):
    """
    Linuxä¸­å›½æœ€æ–°ä¸»é¢˜é€‚é…å™¨
    """
    
    def __init__(
        self,
        source_id: str = "linuxdo-latest",
        name: str = "Linuxä¸­å›½æœ€æ–°",
        **kwargs
    ):
        super().__init__(
            source_id=source_id,
            name=name,
            mode="latest",
            **kwargs
        )


class LinuxDoHotNewsSource(LinuxDoNewsSource):
    """
    Linuxä¸­å›½çƒ­é—¨ä¸»é¢˜é€‚é…å™¨
    """
    
    def __init__(
        self,
        source_id: str = "linuxdo-hot",
        name: str = "Linuxä¸­å›½çƒ­é—¨",
        **kwargs
    ):
        super().__init__(
            source_id=source_id,
            name=name,
            mode="hot",
            **kwargs
        ) 